{"name":"Dice","tagline":"DICE / ColDICE: collisionless phase space hydrodynamics library and solver","body":"\t .----------------.  .----------------.  .----------------.  .----------------.\r\n\t| .--------------. || .--------------. || .--------------. || .--------------. |\r\n\t| |  ________    | || |     _____    | || |     ______   | || |  _________   | |\r\n\t| | |_   ___ `.  | || |    |_   _|   | || |   .' ___  |  | || | |_   ___  |  | |\r\n\t| |   | |   `. \\ | || |      | |     | || |  / .'   \\_|  | || |   | |_  \\_|  | |\r\n\t| |   | |    | | | || |      | |     | || |  | |         | || |   |  _|  _   | |\r\n\t| |  _| |___.' / | || |     _| |_    | || |  \\ `.___.'\\  | || |  _| |___/ |  | |\r\n\t| | |________.'  | || |    |_____|   | || |   `._____.'  | || | |_________|  | |\r\n\t| |              | || |              | || |              | || |              | |\r\n\t| '--------------' || '--------------' || '--------------' || '--------------' |\r\n\t'----------------'  '----------------'  '----------------'  '----------------'\r\nVersion 0.9.44  \r\nCopyright(c) 2015 by Thierry Sousbie. All rights reserved.  \r\nAuthor: Thierry Sousbie - tsousbie[a]gmail[dot]com  \r\n  \r\n  \r\n\r\nDICE is a C++ template library designed to solve collisionless fluid dynamics in 6D phase space using massively parallel supercomputers via an hybrid OpenMP / MPI parallelization. This package implements a cosmological and physical VLASOV-POISSON solver for cold systems such as dark matter (CDM) dynamics called ColDICE and based on DICE.\r\n\r\nIn particular, the following features are implemented in DICE so far:\r\n\r\n   * An MPI distributed unstructured simplicial mesh that can be dynamically refined and coarsened and supporting many additional features (e.g. dynamic load balancing, serialization, multi-threaded iterators, Peano-Hilbert ordering, high order quadratures, ...)\r\n   * A structured AMR (Adaptive mesh refinement) grid.\r\n   * An exact AMR grid raytracer (i.e. the sequence of AMR cells intersected by rays is guaranteed to be exact)\r\n   * Exact 2D and 3D rasterisation via a fast method to project exactly (i.e. by computing exact integrals instead of resorting to random sampling) a first order function defined over the MPI-distributed mesh onto a structured (AMR) grid.\r\n   * A MPI / OpenMP fourier space FFT solver.\r\n   * MPI distributed regular grids with support for complex iterators, various interpolation kernels and high order quadratures.\r\n   * Many other things ...\r\n\r\n\r\n(I) Installation\r\n================\r\nThe DICE template library itself is located in the `include/dice/` directory and features 3 executables:\r\n\r\n* `dice-config`:  \r\n   A utility to retrieve the compilation flags, defines and linker flags used when DICE was configured. This is used to make linking with DICE easy.\r\n\r\n* `netconv`:  \r\n  A utility to convert unstructured mesh outputs to different file formats (e.g. VTK to use with paraview) and unperiodize them.\r\n\r\n* `vtrSlicer`:  \r\n   A utility to extract slices or project fields from .vtr files (VTK format).\r\n\r\nThe Cold dark matter fluid dynamics solver ColDICE is composed of 6 main binaries:\r\n\r\n* `coldice_2D` and `coldice_3D`:  \r\n  The 2D and 3D versions of the vlasov poisson solver\r\n\r\n* `coldicePost_2D` and `coldicePost_3D`:  \r\n  The 2D and 3D versions of utilities used to load restart files produced by coldice_2D and coldice_3D and post process them.\r\n\r\n* `coldiceStatic_2D` and `coldiceStatic_3D`:  \r\n  The 2D and 3D versions of the static potential vlasov poisson solver\r\n\r\nRequirements\r\n------------\r\n\r\n- A recent C++ compiler compatible with C++11 standard (e.g. g++ v4.8.2+ or intel's icpc v11)  \r\n **SEE NOTES BELOW FOR intel compiler users**\r\n- The Eigen library version 3.2.90+ (in external/)\r\n- The Boost library version 1.57+ (the headers suffice, not need to compile it)\r\n- SparseHash libray, already included in the distribution, no need to install it (in external/)\r\n- The FFTW library version 3.3.4+ with optional thread support (if openMP is used) (in external/)\r\n- The GMP library for arbitrary precision arithmetic (you probably have it already) (in external/)\r\n- The Quadruple Double precision library libqd (in external/)  \r\n**SEE NOTES BELOW for intel's compiler users**\r\n\r\n*Additional requirements for MPI support:*  \r\n\r\n- A recent version of the MPI library  \r\n**SEE NOTES BELOW for intel's MPI library users**\r\n- The MPI version of FFTW library version 3.3.4+ (in `external/`)\r\n- The Metis 5.0+ and ParMETIS v4.0+ libraries (in `external/`)\r\n\r\n**IMPORTANT NOTES:**  \r\n\r\n- All necessary libraries can be found in the `external/` sub directory.\r\n- Before installing metis and parmetis, set `IDXTYPEWIDTH 64` in `include/metis.h` and `metis/include/parmetis.h` respectively if required.\r\n- metis and parmetis can be compiled with openmp, but it is not the case by default (make config openmp=1).\r\n- When using intel compiler, Libqd **MUST** be compiled with `-fp-model precise` flag. Not doing so will result in exact projection algorithm failures !!!!\r\n- When using intel MPI library, the code should be compiled with additional option `-mt_mpi` (use `-DCXX_FLAGS_EXTRA=\"-mt_mpi\"` option with cmake)\r\n\r\nInstalling\r\n----------\r\n\r\nInstalling is pretty simple, go to the distribution directory `${DIST_PATH}` and type:\r\n\r\n\tcd build/\r\n\tcmake ../ <options>\r\n\r\nA report will be displayed with default configuration and indications on how to change options (such as the installation path or path to libraries). Typical options are :\r\n\r\n\t-DCMAKE_PREFIX_PATH=<PATH> indicates default path to all libraries\r\n\t-DNO_MPI=true to compile without MPI support\r\n\r\nOther options are indicated in the report. Problems occuring during configuration that may need fixing are reported as red lines in the report together with a hint on what should be done. If such a problem occurs, you may optionally rerun cmake with different options (it is often advised to clean the cache first):\r\n\r\n    cd ../; ./cleanup; cd build/\r\n    cmake ../ <new options>\r\n\r\nOnce everything is set, the code is built by running:\r\n\r\n    make -j N\r\n\r\nwhere N is the number of cores to use in parallel.\r\nUpon completion, the resulting binaries are in `${DIST_PATH}/bin`.\r\nYou can also optionally install the package by running:\r\n\r\n\tmake install\r\n\r\nNOTE:  \r\nIt may sometimes be necessary to clean-up all the files generated by cmake before changing cmake options (e.g. when a library was found but you want to use one from a different location, or when you want to change the compiler). This can be done by running the `cleanup` script from the distribution directory\r\n\r\n    cd ${DIST_PATH}\r\n    ./cleanup\r\n\r\n**IMPORTANT NOTES:**  \r\n\r\n- When using intel compiler, Libqd *MUST* be compiled with `-fp-model precise` flag. Not doing so will result in exact projection algorithm failures !!!!\r\n- When using intel MPI library, the code should be compiled with additional option `-mt_mpi` (use `-DCXX_FLAGS_EXTRA=\"-mt_mpi\"` option with cmake) to enable multi-threading\r\n\r\nUsage\r\n-----\r\n\r\nUsing DICE in a program is relatively easy as it suffice to include relevant header files in your code. Compiling is also made easy thanks to the `dice-config` utility which can be used to retrieve the compiler options necessary to the proper functioning of DICE. To compile a program `dummy.cpp` using DICE, just do:\r\n\r\n    `${DICE_DIR}/bin/dice-config -all` -I${DICE_DIR}/include dummy.cpp -o dummy \t\r\n\r\nwhere `${DICE_DIR}` is the directory where dice was installed (or the directory where it was compiled if you did not install it). Note that `dice-config` can also list flags, defines and libraries individually for more complex projects.\r\n\r\n(II) Documentation\r\n==================\r\n\r\nThe documentation is located in the `${DIST_PATH}/doc` folder and should contain the following:\r\n\r\n - A Doxygen documentation of the library source code can be generated by going to the `doc` subfolder and running `doxygen` from there:\r\n\r\n\t\tcd ${DIST_PATH}/doc\r\n\t\tdoxygen .\r\n The generated documentation can be viewed with any browser (e.g. by running `firefox html/index.html`).\r\n\r\n - A scientific article describing the purpose of and main algorithms in DICE and ColdICE (`article.pdf`). Please reference the published version of this article if you make use of result obtained with this piece of software.\r\n - A `VTK_file_formats.pdf` file containing a description of the output files format. See also http://www.vtk.org/Wiki/VTK_XML_Formats for complementary informations.\r\n - This documentation in PDF format\r\n\r\n\r\n(III) Vlasov-Poisson solvers: `coldice_xD`\r\n==========================================\r\n\r\nRunning:\r\n--------\r\n\r\nParameters for `coldice` programs can be specified directly on the command line preceded by a `-` marker or directly from a parameter file, in which case the parameter file name must be specified as the first argument, without `-` marker. They generaly take the form `<section>.<parameter>` and each parameter can accept one or more arguments, separated by spaces. If a given parameter is not specified, it is given a default value. Information on available parameters, their meaning  and default values can be obtained by running:\r\n\r\n    coldice_nD -help\r\n\r\nor by consulting the appropriate section of this manual. Note however that the list of options given by running the code may be more up-to-date, and it might be convenient to save this documentation to a file by running:\r\n\r\n    coldice_nD -help > parametersDoc.txt\r\n\r\nA typical output will take the form of a list of alphabetically ordered parameters:\r\n\r\n    (...)\r\n    Category: 'mesh'\r\n     ->  mesh.allocFactor = 1\r\n       What fraction of the current number of element to reallocate when a pool is full.\r\n\r\n     ->  mesh.delta[0] = 2\r\n         mesh.delta[1] = 2\r\n         mesh.delta[2] = 0\r\n         mesh.delta[3] = 0\r\n       Size of the initial bounding box\r\n\r\n     ->  mesh.initPartitionTolerance = 1.01\r\n       Tolerance on the load balance of the initial partition\r\n    (...)\r\n\r\nIn this particular example of the 2D version, a parameter `-mesh.delta` that sets the physical size of the initial bounding box is shown to take four arguments at most with default values 2, 2, 0, and 0. New values (e.g. a size of 1 instead of 2) can be specified on the command line as follows:\r\n\r\n    coldice_2D -mesh.delta 1 1\r\n\r\nwhere the unspecified remaining two parameter values will take the default value 0.\r\n\r\nNote that `-help` option lists only the options available with default parameters and specifying some parameters may unlock new available parameters. For instance, the option `-init.type` specifies the initial conditions type and has default value `sineWaves` with following options:\r\n\r\n    Category: 'init'\r\n     ->  init.amplitude[0] = 0.2\r\n         init.amplitude[1] = 0.2\r\n       Amplitude of the sine waves\r\n\r\n     ->  init.nWaves = 1\r\n       Number of waves along each dimensions\r\n\r\n     ->  init.shift[0] = 1\r\n         init.shift[1] = 1\r\n       Sine wave coordinates shift in [0,1]\r\n\r\n     ->  init.velFactor[0] = 0\r\n         init.velFactor[1] = 0\r\n       Velocity to displacement ratio\r\n\r\n     ->  init.velVector[0] = 0\r\n         init.velVector[1] = 0\r\n       Global velocity vector\r\n\r\nChanging `-init.Type` to `cosmo` will change these options, which can be unveiled by running `coldice_2D -init.Type cosmo -help` :\r\n\r\n    Category: 'init'\r\n     ->  init.fileName = ics_gadget.dat\r\n       Gagdet file name (without .N extension for multiple files).\r\n\r\n     ->  init.initTesselationType = ANY\r\n       Topology of the initial grid simplicial tesselation (ALTERNATE,ANY,MINIMAL,REGULAR,USER_DEFINED)\r\n\r\n     ->  init.maxMemPerNode = 1\r\n       The maximum amount of memory to use on each MPI node, expressed in GigaBytes.\r\n\r\n     ->  init.rowMajor = 1\r\n       Use row major particle ordering if true (i.e. index of particle changes faster with X coordinate). Default is rowMinor.\r\n\r\nNote that a summary of the parameter values that will be used for the current run is always given at the end of the output message. A complete list of available parameters is given at the end of this section.\r\n\r\nExamples\r\n--------\r\nA few sample parameters defining initial conditions used in the scientific article `doc/ColDICE.pdf` are given int he `ini/` sub directory:\r\n\r\n  - `chaos.ini`: Evolution of a small square patch in a 2D static chaotic potential (this must be ran with `coldiceStatic_2D`).\r\n  - `sineWaves.ini`: Cosmological collapse of two orthogonal sinusoidal waves.\r\n  - `cosmo.ini`: Simulation of structure formation in a Warm dark matter universe (20 h-1 Mpc scale). A sample script used to run this example over 768 cores is available in `scripts/run_cosmo_occigen`. The initial condition file can be generated using [MUSIC](https://people.phys.ethz.ch/~hahn/MUSIC/) with the parameter file `ini/cosmo.music`. \r\n  - `sineWaves_lowRes.ini`: A low resolution version of `sineWaves.ini` to run on a desktop computer, with regular outputs.\r\n\r\nThe last example (`sineWaves_lowRes.ini`) in particular can be ran on a modest workstation as follows:\r\n\r\n\t\tcoldice_2Dp sineWaves_lowRes.ini -solver.nThreads N -solver.outputDir Dir\r\nWith `N` the number of openMP threads to use and `Dir` the name of the ouput directory where files will be created (pay attention to the fact that this directory must exist prior to running the code). The program should run for up to a few minutes and produce a bunch of output files that can be visualized with [Paraview](http://www.paraview.org/ \"Paraview\") (http://www.paraview.org).  \r\n\r\nNote that the phase-space sheet files need to be un-periodized and converted to the `vtu` format first, which can be done with the following command:\r\n\r\n\t\tfor i in *.NDnet; do netconv $i -unperiodize -to vtu; done\r\n\r\nOutput files\r\n------------\r\nThere are four types of output files :\r\n\r\n  - `dump` files:  \r\n\tOutputs of the current state of the unstructured mesh or projected density / potential in a VTK format readable by paraview or convertible to such a format using `netconv`. The VTK file formats description is available in `${DIST_PATH}/doc/VTK_file_formats.pdf` (see also http://www.vtk.org/Wiki/VTK_XML_Formats). The `.NDnet` [format specifications](http://www2.iap.fr/users/sousbie/web/html/indexceff.html?post/NDnet-format \"NDnet format\") is available at the following URL: http://www2.iap.fr/users/sousbie/web/html/indexceff.html?post/NDnet-format\r\n  - `restart` files (`.rst`):  \r\n\tFiles used to restart runs, see the following section.\r\n  - `statistics.txt`:  \r\n\tContains statistics about the current run such as kinetic and potential energy, time step by time step (see header)\r\n  - `timings.txt`:  \r\n\tTimings of several subparts of the computation during the current run. One file is created for each MPI process in the `timings` subdirectory. The meaning of each column is given in the header.\r\n\r\nRestarting jobs\r\n---------------\r\n\r\nRestart files are produced at regular intervals specified by option `-solver.restartEvery <N>`. These restart files can be used to restart a job from were it was stopped with option `-restart <file name without .rst extension>`. When restarting a job, some parameters may be modified such as the resolution of the grid over which the potential is computed but other are forced to take values given in the initial run such as the mesh resolution. A summay of the \"managed\" parameters values that will be used for the current run is always given as a header in the output of `coldice` before starting computations.\r\n\r\nParameters description\r\n----------------------\r\nAn up-to-date list of parameters can be obtained using the `-help` option, by running `coldice_xD -help` (see list heareafter). Depending on the selected options, new options may be unlocked, these new options can also be listed by running a similar command line of the form `coldice_xD -mycategory.myoption -help`. A list of options given by the command `coldice_xD -help` at the moment this documentation was written follows:\r\n\r\n     Category: 'cosmology'\r\n     ->  cosmology.h0 = 1\r\n       Hubble parameter (h0 = H0 / 100 kms-1 Mpc-1)\r\n  \r\n     ->  cosmology.oB = 0\r\n       Baryonic matter fraction (already included in oM)\r\n  \r\n     ->  cosmology.oL = 0\r\n       Cosmological constant fraction\r\n  \r\n     ->  cosmology.oM = 1\r\n       Matter fraction\r\n  \r\n     ->  cosmology.w = -1\r\n       Equation of state for dark energy\r\n  \r\n     Category: 'default'\r\n     ->  debug = 0\r\n       Set for debug mode (value 0 to 2)\r\n  \r\n     ->  debugHook = 0\r\n       Starts an infinite loop on startup to allow hooking a debugger\r\n  \r\n     ->  debugWait = 0\r\n       Wait for N seconds on startup to allow attaching a debugger\r\n  \r\n     ->  globalLogDir = \r\n       The directory where the global log is created\r\n  \r\n     ->  globalLogFName = globalLog\r\n       The name of the global log file\r\n  \r\n     ->  ignoreUnusedParams = 0\r\n       Do not exit when encountering unknown params\r\n  \r\n     ->  initOnly = 0\r\n       Just initialize, report, and exit\r\n  \r\n     ->  noGlobalLog = 0\r\n       Set to prevent creation of a global log\r\n  \r\n     ->  restart = \r\n       The name of a restart file  \r\n       (without the '.rst' or '_${RANK}.rst'(MPI) extension)\r\n  \r\n     ->  threads_per_node = -1\r\n       The number of openMP threads to use per MPI node (auto set if negative)\r\n  \r\n     ->  verbose = 3\r\n       Verbosity level (from 0=quiet to 4=debug)\r\n  \r\n     Category: 'dump'\r\n     ->  dump.amrAt = \r\n       Sets AMR grid file dumps time interval (fmt: 'start:stop:every').\r\n  \r\n     ->  dump.amrEvery = 0\r\n       Sets AMR grid file dumps time-steps interval \r\n       (dump every N timesteps, never if N negative or 0).\r\n  \r\n\r\n     ->  dump.causticsAt = \r\n       Sets caustics surface sub-mesh file dumps time interval. \r\n       Format is 'start:stop:every'.\r\n  \r\n     ->  dump.causticsEvery = 0\r\n       Sets caustics surface sub-mesh file dumps time-steps interval. \r\n       Dump every N timesteps, never if N negative or 0.\r\n  \r\n     ->  dump.densityAt = \r\n       Sets density grid file dumps time interval (fmt: 'start:stop:every').\r\n  \r\n     ->  dump.densityEvery = 0\r\n       Sets density grid file dumps time-steps interval.\r\n       Dump every N timesteps, never if N negative or 0.\r\n  \r\n     ->  dump.densityProfileCenter[0] = 0\r\n         dump.densityProfileCenter[1] = 0\r\n       The coodinates of the density profile center. Only used if \r\n       specifyProfileCenter is set.\r\n  \r\n     ->  dump.linesAt = \r\n       Sets lagrangian 1D lines sub-mesh file dumps time interval\r\n       (fmt: 'start:stop:every').\r\n  \r\n     ->  dump.linesEvery = 0\r\n       Sets lagrangian 1D lines sub-mesh file dumps time-steps interval \r\n       (dump every N timesteps, never if N negative or 0).\r\n  \r\n     ->  dump.meshAt = \r\n       Sets mesh file dumps time interval (fmt: 'start:stop:every').\r\n  \r\n     ->  dump.meshEvery = 0\r\n       Sets mesh file dumps time-steps interval \r\n       (dump every N timesteps, never if N negative or 0).\r\n  \r\n     ->  dump.potentialAt = \r\n       Sets potential grid file dumps time interval \r\n       (fmt: 'start:stop:every').\r\n  \r\n     ->  dump.potentialEvery = 0\r\n       Sets potential grid file dumps time-steps interval \r\n       (dump every N timesteps, never if N negative or 0).\r\n  \r\n     ->  dump.radialGridDensityAt = \r\n       Sets radial density profile from grid file dumps time interval \r\n       (fmt: 'start:stop:every').\r\n  \r\n     ->  dump.radialGridDensityEvery = 0\r\n       Sets radial density profile from grid file dumps time-steps interval \r\n       (dump every N timesteps, never if N negative or 0).\r\n  \r\n     ->  dump.radialMeshDensityAt = \r\n       Sets radial density profile from mesh file dumps time interval \r\n       (fmt: 'start:stop:every').\r\n  \r\n     ->  dump.radialMeshDensityEvery = 0\r\n       Sets radial density profile from mesh file dumps time-steps interval \r\n       (dump every N timesteps, never if N negative or 0).\r\n  \r\n     ->  dump.reset = 0\r\n       Set this parameters to reset any default file dumps \r\n       (i.e. reset dumps programmed from restart file)\r\n  \r\n     ->  dump.specifyProfileCenter = 0\r\n       Profile is centered on the center of the bounding box if false, or use user specified \r\n       coordinates if true (see densityProfileCenter)\r\n  \r\n     ->  dump.subsetsAt = \r\n       Sets mesh subsets file dumps time interval (fmt: 'start:stop:every').\r\n  \r\n     ->  dump.subsetsEvery = 0\r\n       Sets mesh subsets file dumps time-steps interval (dump every N timesteps, never if N negative or 0).\r\n  \r\n     Category: 'glbDebug'\r\n     ->  glbDebug.meshRefine = 0\r\n       Set to debug mesh refinement.\r\n  \r\n     Category: 'init'\r\n     ->  init.type = sineWaves\r\n       The type of initial condition: uniformGrid, sineWaves, phasedWave, cosmo, composite\r\n       Each type of initial condition is associated to a different set of parameters in the 'init' section\r\n       listed by running `coldice_xD -init.type TYPE -help`. The following parameters are for 'sineWaves'\r\n       initial conditions type.\r\n\r\n     ->  init.amplitude[0] = 2\r\n         init.amplitude[1] = 2\r\n       Amplitude of the sine waves\r\n  \r\n     ->  init.cosmo = 1\r\n       Whether to use cosmology\r\n  \r\n     ->  init.delta[0] = 1\r\n         init.delta[1] = 1\r\n         init.delta[2] = 0\r\n         init.delta[3] = 0\r\n       Size of the initial mesh\r\n  \r\n     ->  init.initTesselationType = ANY\r\n       Topology of the initial grid simplicial tesselation (ALTERNATE,ANY,MINIMAL,REGULAR,USER_DEFINED)\r\n  \r\n     ->  init.resolution[0] = 64\r\n         init.resolution[1] = 64\r\n       Resolution of the initial mesh (in pixels before tesselation)     \r\n  \r\n     ->  init.x0[0] = -0.5\r\n         init.x0[1] = -0.5\r\n         init.x0[2] = 0\r\n         init.x0[3] = 0\r\n       Initial coordinates of the mesh lower left corner\r\n  \r\n\r\n     Category: 'mesh'\r\n     ->  mesh.allocFactor = 1\r\n       What fraction of the current number of element to reallocate when a pool is full.\r\n  \r\n     ->  mesh.delta[0] = 1\r\n         mesh.delta[1] = 1\r\n         mesh.delta[2] = 0\r\n         mesh.delta[3] = 0\r\n       Size of the bounding box\r\n  \r\n     ->  mesh.initPartitionTolerance = 1.01\r\n       Tolerance on the load balance of the initial partition\r\n  \r\n     ->  mesh.initPartitionType = KWAY\r\n       The method to use for initial partitionning (KWAY,PH,PH_KWAY)\r\n  \r\n     ->  mesh.refinePartitionType = ADAPTIVE\r\n       The method to use for repartitionning (ADAPTIVE,KWAY,PH,REFINE_KWAY)\r\n  \r\n     ->  mesh.repartThreshold = 1.15\r\n       Inbalance factor that triggers repartitionning\r\n  \r\n     ->  mesh.repartTolerance = 1.01\r\n       Tolerance on the load balance after repartitionning\r\n  \r\n     ->  mesh.x0[0] = -0.5\r\n         mesh.x0[1] = -0.5\r\n         mesh.x0[2] = 0\r\n         mesh.x0[3] = 0\r\n       Initial coordinates of the bounding box lower left corner\r\n      \r\n     Category: 'projection'\r\n     ->  projection.accuracyLevel = 0.001\r\n       Required accuracy level for projection (DISABLED). \r\n       Use D_ENABLE_ACCURACY_CHECKING compile time option to enable.\r\n  \r\n     ->  projection.anisotropyThreshold = 1e+06\r\n       The simplex anisotropy threshold up to which exact projection is used \r\n       (expressed as the maximum to minimum simplex extent ratio)\r\n  \r\n     ->  projection.enableHRModeThreshold = 0\r\n       Fraction of the simplices that are allowed to be reprojected before definitively switching to high \r\n       resolution projection mode (between 0 and 1, negative number=>always).\r\n  \r\n     ->  projection.resetHRMode = 0\r\n       Ignore whether high resolution mode was set on a previous run and set it to false. \r\n       This is only meaningfull when restarting a run.\r\n  \r\n     ->  projection.useVerticesThreshold = -1\r\n       Minimum refinement level of a simplex above which its vertices are used to project it instead of \r\n       exact integration. This should be equal to either '-1' or the value of 'solver.maxSimplexLevel'.\r\n  \r\n     ->  projection.widthThreshold = 1e-07\r\n       The width of an element, expressed as a fraction of the bounding box size, down to which \r\n       exact projection is used.\r\n  \r\n     Category: 'solver'\r\n     ->  solver.aEnd = 1\r\n       Final value of the scale factor\r\n  \r\n     ->  solver.aStart = 0.01\r\n       Initial value of the scale factor\r\n  \r\n     ->  solver.cflCondition = CFL_RHOMAX\r\n       CFL condition type (CFL,CFL_RHOMAX,NONE,RHOMAX)\r\n  \r\n     ->  solver.cflGrid = 0.25\r\n       Value of the CFL condition (fraction of a FFT grid pixel size)\r\n  \r\n     ->  solver.cflRhoMax = 0.01\r\n       Value of the maximum density condition (fraction of an orbit size)\r\n  \r\n     ->  solver.checkProjectedDensity = 1\r\n       Check the positivity of the projected density (also look for NaN values).\r\n  \r\n     ->  solver.coarsenEvery = 1\r\n       Force coarsening every N timesteps\r\n  \r\n     ->  solver.coarsenHysteresis = 0.95\r\n       NOT used\r\n  \r\n     ->  solver.cosmo = 1\r\n       Use cosmological expansion ?\r\n  \r\n     ->  solver.dLogA = 0.1\r\n       Maximum value for d(log(a))=da/a.\r\n  \r\n     ->  solver.dumpInitialMesh = 0\r\n       Dump the mesh right after creating the initial conditions.\r\n  \r\n     ->  solver.dumpRestartSignalFileName = DUMP_RESTART\r\n       The name of the file to create in the output directory in order to force the creatioàn of a restart \r\n       file on next time step.\r\n  \r\n     ->  solver.exportFftWisdom = wisdom.fftw\r\n       The name of a file to which the acquired FFTW wisdom will be exported. Set to 'SKIP' or 'skip' to \r\n       prevent exportation.\r\n  \r\n     ->  solver.fastAmrBuild = 1\r\n       If true, refine the AMR grid so that it only fits roughly the resolution of the mesh. This is \r\n       probably always good enough and much faster ...\r\n  \r\n     ->  solver.fftGridLevel = 8\r\n       Size of the FFT grid used for the Poisson solver (effective size is 2^fftGridLevel)\r\n  \r\n     ->  solver.fftWisdom = 1\r\n       Which level of FFTWISDOM to use, in the range {0,1,2,3}={ESTIMATE,MEASURE,PATIENT,EXHAUSTIVE}. \r\n       The higher the faster, but the slower the initialization ...\r\n  \r\n     ->  solver.importFftWisdom = wisdom.fftw\r\n       The name of a file from which FFTW wisdom will be imported. Set to 'SKIP' or 'skip' to \r\n       prevent importation.\r\n  \r\n     ->  solver.invariantThreshold = 1e-05\r\n       Poincare invariant threshold to trigger refinement\r\n  \r\n     ->  solver.mass = 1\r\n       Initial total mass\r\n  \r\n     ->  solver.maxAmrLevel = 8\r\n       Maximum refinement level of the AMR grid (don't touch that, it's already set ;) )\r\n  \r\n     ->  solver.maxSimplexLevel = -1\r\n       Maximum level of refinement a simplex is allowed to reach.\r\n       (-1  for no maximum, unrefined simplices have level 0)\r\n       See also 'projection.useVerticesThreshold'.\r\n  \r\n     ->  solver.nThreads = 4\r\n       The number of threads to use per process. This parameter will override the default 'threads_per_node' \r\n       parameter and will be saved from one run to another.\r\n  \r\n     ->  solver.noCoarsen = 1\r\n       Set to prevent mesh coarsening\r\n  \r\n     ->  solver.noRefine = 0\r\n       Set to prevent mesh refinement\r\n  \r\n     ->  solver.noRepartWeight = 1\r\n       If true, MPI regions weight is directly proportional to the number of simplices.\r\n  \r\n     ->  solver.noRestart = 0\r\n       Set to prevent from dumping any restart file.\r\n  \r\n     ->  solver.outputDir = \r\n       The directory where all files will be put (default is './', directory must exist)\r\n  \r\n     ->  solver.phSortThreshold = 0.05\r\n       Maximum allowed ratio of randomly distributed to ordered cells before triggering a Peano-Hilbert \r\n       sort of the local meshes.\r\n  \r\n     ->  solver.projectionOrder = 1\r\n       Order of the exact mass projection (only 0 and 1 are implemented so far)\r\n  \r\n     ->  solver.rebuildAmrEvery = 1\r\n       How many timestep to wait before entirely rebuilding the AMR grids. \r\n       (IGNORED : not implemented yet!)\r\n  \r\n     ->  solver.refineThreshold = 3\r\n       NOT used\r\n  \r\n     ->  solver.resimulate = 0\r\n       Set to start a resimulation after the simulation completes\r\n  \r\n     ->  solver.resimulateEvery = 0\r\n       Not implemented\r\n  \r\n     ->  solver.restartEvery = 50\r\n       Write a restart file every N timestep (no restart is written if N negative or 0)\r\n  \r\n     ->  solver.skipInitialPoisson = 1\r\n       Skips the pre-solving of poisson equation for when the CFL conditon is set to CFL_RHOMAX. \r\n       Instead, measure initial RHOMAX directly on the sheet.\r\n  \r\n     ->  solver.splitLongestEdge = 0\r\n       Set to split the longest longest edge when refining instead of trying to minimize the invariant\r\n  \r\n     ->  solver.squeezeMesh = 0\r\n       You don't want to know ;)\r\n  \r\n     ->  solver.statisticsFileName = statistics.txt\r\n       The name of the file where statistics will be stored\r\n  \r\n     ->  solver.stopSignalFileName = STOP\r\n       The name of the file to create in the output directory in order to cleanly stop the run.\r\n  \r\n     ->  solver.symmetry = NONE\r\n       Type of symmetry to enforce.\r\n       (AXIAL0,AXIAL01,AXIAL012,AXIAL02,AXIAL1,AXIAL12,AXIAL2,CENTRAL,CONSTANT0,CONSTANT1,CONSTANT2,NONE,\r\n       PLANAR0,PLANAR01,PLANAR012,PLANAR02,PLANAR1,PLANAR12,PLANAR2)\r\n       THIS OPTION DOES NOT WORK PROPERLY WITH MPI YET !\r\n  \r\n     ->  solver.timeLimit = -1\r\n       CPU time limit (in hours, will stop before spending it). This is an exact limit (negative for no limit). \r\n       See also timeLimitSafety\r\n  \r\n     ->  solver.timeLimitSafety = 0.95\r\n       Fraction of the timeLimit while it is safe to keep computing. Leaves (1-timeLimitSafety)*timeLimit \r\n       for writing the restart file.\r\n  \r\n     ->  solver.timingsFileName = timings.txt\r\n       The name of the file where timings will be stored\r\n  \r\n     ->  solver.volumeThreshold = 1e+10\r\n       Volume threshold to trigger refinement (NOT used)\r\n  \r\n     Category: 'units'\r\n     ->  units.H = 1\r\n       Hubble parameter (default value in s-1).\r\n  \r\n     ->  units.length = 1\r\n       Length unit expressed in meters (default: -).\r\n  \r\n     ->  units.mass = 1\r\n       Mass unit expressed in meters (default: -).\r\n  \r\n     ->  units.velocity = 1\r\n       Velocity unit expressed in meters (default: -).\r\n  \r\nInitial conditions\r\n------------------\r\nThere are currently 5 types of initial conditions implemented in the code. Additionally to these initial conditions, it should be relatively easy to implement your own. If you want to do so, check the `IC_dummy.hxx` file provided in the `${DICE_DIR}/solvers/ColDICE/init/` directory.  \r\n  \r\nCurrently implemented initial conditions are:\r\n\r\n- `uniformGrid`: A flat uniform grid that can be advected by a static potential.\r\n- `sineWaves`: Two orthogonal sinusoidal overdensities. Can be used with physical or cosmological conditions.\r\n- `phasedWaves`: A distorted plane wave. Can be used with physical or cosmological conditions\r\n- `cosmo`: cosmological initial conditions read from a `gadget` type file as generated e.g. with MUSIC (https://people.phys.ethz.ch/~hahn/MUSIC/)\r\n- `composite`: the composition of several grids for simulating e.g. interacting objects. This is quite rudimentary at the moment !\r\n\r\nSpecific parameters are associated to each type of initial conditions. The following list was obtained by running `coldice_xD -init.type <TYPE> -help`:    \r\n  \r\n\r\n`TYPE=cosmo`: \r\n\r\n     ->  init.fileName = ics_gadget.dat\r\n       Gagdet file name (without .N extension for multiple files).\r\n\r\n     ->  init.initTesselationType = ANY\r\n       Topology of the initial grid simplicial tesselation \r\n       (ALTERNATE,ANY,MINIMAL,REGULAR,USER_DEFINED)\r\n\r\n     ->  init.maxMemPerNode = 1\r\n       The maximum amount of memory to use on each MPI node, expressed in GigaBytes.\r\n       Default is 1GB per node.\r\n\r\n     ->  init.rowMajor = 1\r\n       Use row major particle ordering if true (i.e. index changes faster with X coordinate). \r\n       Default is rowMajor.\r\n\r\n     ->  init.x0[0] = 0\r\n         init.x0[1] = 0\r\n       Position of the lower left corner of the box\r\n\r\n`TYPE=sineWaves`: \r\n\r\n     ->  init.amplitude[0] = 2\r\n         init.amplitude[1] = 2\r\n       Amplitude of the sine waves\r\n\r\n     ->  init.cosmo = 1\r\n       Whether to use cosmology\r\n\r\n     ->  init.delta[0] = 1\r\n         init.delta[1] = 1\r\n         init.delta[2] = 0\r\n         init.delta[3] = 0\r\n       Size of the initial mesh\r\n\r\n     ->  init.initTesselationType = ANY\r\n       Topology of the initial grid simplicial tesselation \r\n       (ALTERNATE,ANY,MINIMAL,REGULAR,USER_DEFINED)\r\n\r\n     ->  init.resolution[0] = 64\r\n         init.resolution[1] = 64\r\n       Resolution of the initial mesh (in pixels before tesselation)\r\n\r\n     ->  init.x0[0] = -0.5\r\n         init.x0[1] = -0.5\r\n         init.x0[2] = 0\r\n         init.x0[3] = 0\r\n       Initial coordinates of the mesh lower left corner\r\n\r\n`TYPE=phasedWaves`\r\n\r\n     ->  init.aCross = 0.15\r\n       Time of first shell crossing\r\n\r\n     ->  init.delta[0] = 100\r\n         init.delta[1] = 100\r\n         init.delta[2] = 0\r\n         init.delta[3] = 0\r\n       Size of the initial mesh\r\n\r\n     ->  init.epsilon = 0.5\r\n     \r\n     ->  init.initTesselationType = ANY\r\n       Topology of the initial grid simplicial tesselation \r\n       (ALTERNATE,ANY,MINIMAL,REGULAR,USER_DEFINED)\r\n\r\n     ->  init.k = 1\r\n       Perturbation parameter\r\n\r\n     ->  init.kp = 1\r\n       Plane wave parameter\r\n\r\n     ->  init.resolution[0] = 64\r\n         init.resolution[1] = 64\r\n       Resolution of the initial mesh (in pixels before tesselation)\r\n\r\n     ->  init.x0[0] = 0\r\n         init.x0[1] = 0\r\n         init.x0[2] = 0\r\n         init.x0[3] = 0\r\n       Initial coordinates of the mesh lower left corner\r\n\r\n`TYPE=composite`: \r\n\r\n     ->  init.add = none\r\n       The type of component to add (only 'box' is available now) . Can be called several times ...\r\n\r\n     ->  init.bBoxDelta[0] = 2\r\n         init.bBoxDelta[1] = 2\r\n         init.bBoxDelta[2] = 0\r\n         init.bBoxDelta[3] = 0\r\n       Size of the bounding box\r\n\r\n     ->  init.bBoxX0[0] = -1\r\n         init.bBoxX0[1] = -1\r\n         init.bBoxX0[2] = 0\r\n         init.bBoxX0[3] = 0\r\n       Initial coordinates of the bounding box lower left corner\r\n\r\n\r\n(IV) Solvers post-reatment from restart files: `coldicePost_xD`\r\n=============================================================\r\n`coldicePost_xD` programs are similar to the `coldice_xD` ones but are adapted to the post-treatment of restart files produced by `coldice_xD`. They work exactly the same as coldice programs and take the same arguments as `coldice_xD` plus a few additional ones in the \"post\" section (i.e. of the form `post.<option>`). This program is typically run as:\r\n\r\n\tcoldicePost_xD -restart <FILENAME without `_XXXX.rst` extension> -post.option...\r\n\r\nand all options available in the `post` section can be listed  by running `coldicePost_xD -help`:\r\n\r\n     Category: 'post'\r\n     ->  post.dumpAmr = 0\r\n       Whether to dump AMR files.\r\n\r\n     ->  post.dumpDensity = 0\r\n       Whether to dump density grid files\r\n\r\n     ->  post.dumpMesh = 0\r\n       Whether to dump the unstructured mesh files\r\n\r\n     ->  post.dumpRadialGridDensity = 0\r\n       Whether to dump the radial grid density (from projected grid)\r\n\r\n     ->  post.dumpRadialMeshDensity = 0\r\n       Whether to dump the radial mesh density (from the mesh)\r\n\r\n     ->  post.dumpSubmesh = 0\r\n       Whether to dump the unstructured mesh subsets files\r\n\r\n     ->  post.gridLevel = 8\r\n       Sets the resolution of the density grid\r\n\r\n     ->  post.projectionOrder = 1\r\n       Order of the exact mass projection (0 or 1)\r\n\r\n     ->  post.radialMeshDensitySamples = 10\r\n       The number of samples to use per overlap for radial mesh density computation\r\n\r\n     ->  post.refineMesh = 0\r\n       Refine the mesh using tracers.\r\n\r\n\r\n\r\n(V) Static potential Vlasov-poisson solvers: `coldiceStatic_xD`\r\n==============================================================\r\n`coldiceStatic_xD` programs are similar to `coldice_xD` ones but work with a static potential for which an analytic solution is known. They work exactly the same as coldice programs and take the same arguments plus a few additional ones in the `staticSolver` section (i.e. of the form `staticSolver.<option>`). These parameters can also be listed with the \"-help\" option :\r\n\r\n    Category: 'staticSolver'\r\n      ->  staticSolver.gravitationalMass = 1\r\n        Total mass generating the static potential\r\n\r\n      ->  staticSolver.potential = PLUMMER\r\n        Static potential type (CHAOTIC,PLUMMER,UDF)\r\n\r\nand a few parameters are associated to each type of potential, listed in the `potential` section. For instance, the parameters associated to the `CHAOTIC` potential are obtained by runnning `coldiceStatic_xD -staticSolver.potential CHAOTIC -help`:\r\n   \r\n    Category: 'potential'\r\n      ->  potential.Rc = 0.2\r\n        Central radius\r\n\r\n      ->  potential.epsilon = 0.5\r\n        Perturbation amplitude (epsilon=0 -> regular orbits)\r\n\r\n      ->  potential.q = 0.9\r\n        Excentricity\r\n\r\n\r\n(VI) Unstructured mesh output files manipulation : `netconv`\r\n===========================================================\r\nnetconv is used to converted unstructured mesh outputs in `.NDnet` format to other formats and/or unperiodizing the mesh for visualization. A short documentation can be obtained by running `netconv -help`, and it is typically used to convert files to the `vtu` format that can be visualized with `paraview` :\r\n\r\n\tnetconv <NDnet filename> [-unperiodize] -to vtu\r\n\r\nwhere the `unperiodize` option can be specified to explicitly break periodic boundary conditions that would otherwise produce visual artefacts.\r\n\r\n\r\n(VII) Troubleshooting\r\n=====================\r\n\r\n - An MPI run crashes at \"Gathering potential ...\"  \r\n  This may be a MPI configuration problem, if you are using openMPI, try setting `export OMPI_MCA_mpi_leave_pinned=0`, or try finding an equivalent option for your MPi implementation.\r\n\r\n - You get the \"Negative or NaN values found for the projected mass in xxx voxel(s).\" ERROR (not the WARNING), followed by a message saying there may be a bug, and the code stops.  \r\n  If you are using an Intel compiler, you must compile libQD with the `-fp-model precise` flag enabled (DICE solvers should automatically have it, check the compile flags to make sure). If you get this message only once or twice in a very long MPI run, and the code does not stop, don't worry, the code is running fine.\r\n\r\n - You get an error message at startup saying \"This MPI implementation does not support any type of multithreading\".  \r\n  If you are using the Intel compiler, you must add the `-mt_mpi` compile flag to enable a minimal level of multithreading capability (use `-DCXX_FLAGS_EXTRA=\"-mt_mpi\"` option with cmake)\r\n\r\n","google":"UA-67548297-2","note":"Don't delete this file! It's used internally to help with page regeneration."}